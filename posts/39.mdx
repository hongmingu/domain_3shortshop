---
title: Kotlin 동영상 편집 기초 1
description: "Kotlin으로 동영상 편집 앱 만들기 1"
date: August 1 2023
---
동영상 편집 기능을 구현하려면 Android의 MediaExtractor, MediaMuxer, MediaCodec 클래스를 사용할 수 있다. 
하지만 이러한 클래스들은 상당히 복잡하고 동영상 편집의 모든 기능을 직접 구현하는 조금 어려운 일이다

그러므로 라이브러리를 쓰자.


### 라이브러리 설치
먼저 프로젝트의 build.gradle 파일에 MP4Parser 라이브러리를 추가한다

```
dependencies {
    implementation 'org.mp4parser:isoparser:1.9.41'
}

```

#### 동영상 클립 합치기

```
import com.coremedia.iso.boxes.Container
import com.googlecode.mp4parser.FileDataSourceImpl
import com.googlecode.mp4parser.authoring.Movie
import com.googlecode.mp4parser.authoring.builder.DefaultMp4Builder
import com.googlecode.mp4parser.authoring.container.mp4.MovieCreator
import com.googlecode.mp4parser.authoring.tracks.AppendTrack
import java.io.File
import java.io.FileOutputStream
import java.io.IOException

@Throws(IOException::class)
fun mergeVideos(videos: List<File>, output: File) {
    val movies = ArrayList<Movie>()
    for (video in videos) {
        movies.add(MovieCreator.build(FileDataSourceImpl(video.absolutePath)))
    }

    val videoTracks = LinkedList<Track>()
    val audioTracks = LinkedList<Track>()

    for (movie in movies) {
        for (track in movie.tracks) {
            if (track.handler == "soun") {
                audioTracks.add(track)
            }
            if (track.handler == "vide") {
                videoTracks.add(track)
            }
        }
    }

    val videoResultTrack = AppendTrack(*videoTracks.toTypedArray())
    val audioResultTrack = AppendTrack(*audioTracks.toTypedArray())

    val resultMovie = Movie()
    resultMovie.addTrack(videoResultTrack)
    resultMovie.addTrack(audioResultTrack)

    val out = DefaultMp4Builder().build(resultMovie)
    val fc = FileOutputStream(output).channel
    out.writeContainer(fc)
    fc.close()
}

```

이 코드는 여러 동영상 파일을 입력 받아 하나의 동영상 파일로 합치는 기능을 수행한다.
 mergeVideos 함수는 동영상 파일들을 File 객체의 리스트로 입력 받아 모든 동영상의 비디오 트랙과 오디오 트랙을 추출하고 이 트랙들을 합쳐 새로운 동영상 파일을 만든다.

이 함수를 사용하려면 먼저 동영상 파일들을 File 객체의 리스트로 만들고 출력 파일도 File 객체로 만든 후 이들을 mergeVideos 함수에 전달하면 된다.


### 동영상 크롭하기

라이브러리를 사용하여 이를 수행하는 간단한 방법 중 하나는 FFmpeg을 이용하는 것이다. 
FFmpeg은 동영상 및 오디오 처리를 위한 툴로 Android에서도 사용 가능하다.

#### 라이브러리 설치

```
dependencies {
    implementation 'com.arthenica:mobile-ffmpeg-full:4.4.LTS'
}
```

그런 다음 FFmpeg 명령어를 사용하여 동영상을 크롭할 수 있다

```
import com.arthenica.mobileffmpeg.FFmpeg

//...

fun cropVideo(inputPath: String, outputPath: String, x: Int, y: Int, width: Int, height: Int) {
    val command = "-i $inputPath -filter:v \"crop=$width:$height:$x:$y\" -c:a copy $outputPath"
    val returnCode = FFmpeg.execute(command)

    if (returnCode == RETURN_CODE_SUCCESS) {
        Log.i(Config.TAG, "Command execution completed successfully.")
    } else if (returnCode == RETURN_CODE_CANCEL) {
        Log.i(Config.TAG, "Command execution cancelled by user.")
    } else {
        Log.i(Config.TAG, String.format("Command execution failed with rc=%d and the output below.", returnCode))
        Config.printLastCommandOutput(Log.INFO)
    }
}

```

이 함수는 입력 동영상의 경로, 출력 동영상의 경로, 크롭 시작 위치의 x와 y 좌표(x, y), 
크롭 영역의 너비와 높이(width, height)를 매개변수로 받는다.

이 함수를 사용하려면 원하는 동영상의 경로와 크롭 영역의 좌표 및 크기를 지정하여 cropVideo 함수를 호출하면 된다.

### 모자이크 처리

동영상에 모자이크가 필요할 수 있다.

이 역시 FFmpeg를 이용한다.


```
import com.arthenica.mobileffmpeg.FFmpeg

// ...

fun applyMosaic(inputPath: String, outputPath: String, x: Int, y: Int, width: Int, height: Int) {
    val command = "-i $inputPath -filter:v \"drawbox=x=$x:y=$y:w=$width:h=$height:color=black@0:t=fill,boxblur=10\" $outputPath"
    val returnCode = FFmpeg.execute(command)

    if (returnCode == RETURN_CODE_SUCCESS) {
        Log.i(Config.TAG, "Command execution completed successfully.")
    } else if (returnCode == RETURN_CODE_CANCEL) {
        Log.i(Config.TAG, "Command execution cancelled by user.")
    } else {
        Log.i(Config.TAG, String.format("Command execution failed with rc=%d and the output below.", returnCode))
        Config.printLastCommandOutput(Log.INFO)
    }
}

```

이 함수는 입력 동영상, 출력 동영상의 경로, 모자이크를 적용할 영역의 x와 y 좌표(x, y), 모자이크를 적용할 영역의 너비와 높이(width, height)를 매개변수로 받는다.

이 함수는 먼저 drawbox 필터를 사용하여 모자이크를 적용할 영역에 투명한 검은색 상자를 그린 후 boxblur 필터를 사용하여 해당 영역을 흐리게 한다. 
boxblur=10의 값은 모자이크의 정도를 나타내는데 이 값을 높일수록 더 흐릿한 모자이크가 적용된다.

원하는 동영상의 경로와 모자이크를 적용할 영역의 좌표 및 크기를 지정하여 applyMosaic 함수를 호출하면 된다.

### 백그라운드 스레드에서 실행하기

안드로이드 앱의 메인 스레드는 사용자 인터페이스와 상호작용하고 이벤트를 처리하는 역할이다. 
이 스레드에서 시간이 오래 걸리는 작업을 실행하면 사용자 인터페이스가 멈추거나 에러 메시지가 표시될 수 있다. 
이를 방지하기 위해 시간이 오래 걸리는 작업은 다른 스레드에서 실행하는데 이걸 백그라운드 스레드라고 한다.



```
import kotlinx.coroutines.Dispatchers
import kotlinx.coroutines.withContext
import com.arthenica.mobileffmpeg.FFmpeg

// ...

suspend fun runFFmpegCommandInBackground(command: String): Int {
    return withContext(Dispatchers.IO) {
        FFmpeg.execute(command)
    }
}

```

이 함수는 withContext 함수와 Dispatchers.IO 디스패처를 사용하여 FFmpeg 명령을 백그라운드 스레드에서 실행한다. 
이 함수를 호출하는 코루틴은 withContext 함수가 반환될 때까지 즉 FFmpeg 명령이 완료될 때까지 일시정지된다.

이 함수는 suspend 키워드로 선언되어 코루틴에서만 호출할 수 있다. 
이를 통해 앱의 메인 스레드에서 무심코 이 함수를 호출하여 앱이 멈추는 상황을 방지할 수 있다. 
이 함수를 호출하려면 launch 또는 async 같은 함수를 사용하여 코루틴을 생성해야 한다.

launch는 새로운 코루틴을 시작하고, 결과를 반환하지 않는다. 
이는 'fire-and-forget' 형태의 비동기 작업에 적합하다.

```
import kotlinx.coroutines.*

fun main() = runBlocking { 
    launch { 
        delay(1000L) 
        println("Hello from launched coroutine!") 
    } 
    println("Hello from main thread!") 
}

```

위 코드에서 launch는 새로운 코루틴을 시작하고 즉시 반환한다. 
따라서 "Hello from main thread!"가 먼저 출력되고 1초 후에 "Hello from launched coroutine!"가 출력된다.

async는 새로운 코루틴을 시작하고 Deferred를 반환한다. 
이 Deferred는 나중에 결과를 가져올 수 있는 객체이다. 
이는 비동기 작업의 결과를 기다려야 하는 경우에 적합하다.
Promise await 구문과 비슷하다.

```
import kotlinx.coroutines.*

fun main() = runBlocking {
    val deferred = async { 
        delay(1000L) 
        "Hello from async coroutine!" 
    } 
    println("Hello from main thread!") 
    println(deferred.await()) 
}

```

위 코드에서 async는 새로운 코루틴을 시작하고 Deferred를 반환한다. 
이 Deferred의 await 메서드를 호출하면 결과가 준비될 때까지 대기한 후 결과를 가져온다. 
따라서 "Hello from main thread!"가 먼저 출력되고 1초 후에 "Hello from async coroutine!"가 출력된다.